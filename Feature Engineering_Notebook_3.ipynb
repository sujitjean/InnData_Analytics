{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering:\n",
    "\n",
    "In this section we will perform feature engineering some of the things we will perfrom are listed below\n",
    "\n",
    "1. Add in the log transformation of the numerical variables\n",
    "2. One-hot encode the categorical variables\n",
    "3. Remove the Colinear features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\Sujit\\Energy_Star_Score of a building\\preprocessed.csv\")\n",
    "data = data.rename(columns = {'ENERGY STAR Score': 'score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "D:\\Installed\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "D:\\Installed\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Selecting only the numerical values and then we will iterate through all the numerical values .\n",
    "\n",
    "then transform the values into the LOG of the features , we have already discueed why this done.\n",
    "\n",
    "\"\"\"\n",
    "numeric_subset = data.select_dtypes('number')\n",
    "\n",
    "for col in numeric_subset.columns:\n",
    "    if col == 'score':\n",
    "        next\n",
    "    else:\n",
    "        numeric_subset['log_' + col] = np.log(numeric_subset[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11746, 115)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "now seleting all the categorial values and then vectorize them as one hot encodings so that we represent them as numnerical\n",
    "features \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "categorical_subset = data[['Borough', 'Largest Property Use Type']]\n",
    "\n",
    "\"\"\"\n",
    "here to cectorise we can use any vectorizer like Count vectorizer and all .\n",
    "\n",
    "\"\"\"\n",
    "categorical_subset = pd.get_dummies(categorical_subset)\n",
    "\n",
    "# Join the two dataframes using concat\n",
    "# Make sure to use axis = 1 to perform a column bind\n",
    "features = pd.concat([numeric_subset, categorical_subset], axis = 1)\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Utility function to remove all the collinear features from the dataset .\n",
    "\n",
    "and this function has two inputs\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def collinear_features(x, threshold):\n",
    "    y = x['score']\n",
    "    x = x.drop(columns = ['score'])\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Looping over every comluns finding the colinearity .\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    for i in iters:\n",
    "        for j in range(i):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \"\"\"\n",
    "    will only keep the features that has higher threshold than 0.6, and the others will be droped \n",
    "    \n",
    "    \"\"\"\n",
    "    if val >= threshold:\n",
    "        drop_cols.append(col.values[0])\n",
    "    \"\"\"\n",
    "    \n",
    "    Now droping all the values that have a higer corelation among them slef as we have seen in the Corealltion metrix in the \n",
    "    Exploratory Data Analysis , as we want only to keep the values which has higher corelation with the target values. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns = drops)\n",
    "    x = x.drop(columns = ['Weather Normalized Site EUI (kBtu/ft²)','Water Use (All Water Sources) (kgal)','log_Water Use (All Water Sources) (kgal)',\n",
    "                          'Largest Property Use Type - Gross Floor Area (ft²)'])\n",
    "\n",
    "    x['score'] = y\n",
    "               \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "now we are removing all the fetaure with a thershold of Grater than 0.6 becasue when the features have high corealltion \n",
    "between them selfs then it no point in having them .\n",
    "\n",
    "\"\"\"\n",
    "features = collinear_features(features, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1858, 65)\n",
      "(9461, 65)\n"
     ]
    }
   ],
   "source": [
    "no_score = features[features['score'].isna()]\n",
    "score = features[features['score'].notnull()]\n",
    "\n",
    "print(no_score.shape)\n",
    "print(score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = score.drop(columns='score')\n",
    "targets = pd.DataFrame(score['score'])\n",
    "features = features.replace({np.inf: np.nan, -np.inf: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6622, 64)\n",
      "(2839, 64)\n",
      "(6622, 1)\n",
      "(2839, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "we should consider the test and train split of data as 70 - 30 ratio or 80 -20 ratio for better Genaralization\n",
    "\n",
    "\n",
    "if it was calssification then for spliting we can use the stratified split but regreesion so not required \n",
    "\"\"\"\n",
    "X, X_test, y, y_test = train_test_split(features, targets, test_size = 0.3)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "print(y.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('training_data.csv', index = False)\n",
    "X_test.to_csv('testing_data.csv', index = False)\n",
    "y.to_csv('training_target.csv', index = False)\n",
    "y_test.to_csv('testing_target.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
